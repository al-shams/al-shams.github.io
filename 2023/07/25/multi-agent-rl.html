<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title>Ali Shamsadini | Multi-Agent Deep Reinforcement Learning-Based Framework
        for Resource Management in Self-Organizing Networks</title>
    <!-- Bootstrap core CSS -->
    <link href="/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <!-- Custom styles for this template -->
    <link rel="stylesheet" href="/assets/css/styles.css">
    <link rel="stylesheet" href="/assets/css/syntax.css">
    <link rel="shortcut icon" type="image/x-icon" href="/assets/images/favicon.svg?">
    <!-- Begin Jekyll SEO tag v2.6.1 -->
    <title>Multi-Agent Deep Reinforcement Learning-Based Framework
        for Resource Management in Self-Organizing Networks | Ali Shamsadini</title>
    <meta name="generator" content="Jekyll v4.0.0"/>
    <meta property="og:title"
          content="Multi-Agent Deep Reinforcement Learning-Based Framework for Resource Management in Self-Organizing Networks"/>
    <meta property="og:locale" content="en_US"/>
    <meta name="description"
          content="Reinforcement Learning (RL) has demonstrated its capabilities in designing effective logic within controlled environments. However, exploring its applications in more complex domains, such as telecom networks, presents exciting possibilities."/>
    <meta property="og:description"
          content="Reinforcement Learning (RL) has demonstrated its capabilities in designing effective logic within controlled environments. However, exploring its applications in more complex domains, such as telecom networks, presents exciting possibilities."/>
    <link rel="canonical" href="https://al-shams.github.io/2023/07/25/multi-agent-rl.html"/>
    <meta property="og:url" content="https://al-shams.github.io/2023/07/25/multi-agent-rl.html"/>
    <meta property="og:site_name" content="Ali Shamsadini"/>
    <meta property="og:type" content="article"/>
    <meta property="article:published_time" content="2023-07-25T00:00:00-05:00"/>
    <script type="application/ld+json">
        {
            "headline": "Multi-Agent Deep Reinforcement Learning-Based Framework for Resource Management in Self-Organizing Networks",
            "dateModified": "2023-07-26T00:00:00-05:00",
            "datePublished": "2023-07-26T00:00:00-05:00",
            "url": "https://al-shams.github.io/2023/07/25/multi-agent-rl.html",
            "mainEntityOfPage": {
                "@type": "WebPage",
                "@id": "https://al-shams.github.io/2023/07/25/multi-agent-rl.html"
            },
            "description": "Reinforcement Learning (RL) has demonstrated its capabilities in designing effective logic within controlled environments. However, exploring its applications in more complex domains, such as telecom networks, presents exciting possibilities.",
            "@type": "BlogPosting",
            "@context": "https://schema.org"
        }</script>
    <!-- End Jekyll SEO tag -->
</head>
<body>
<!-- Navigation -->
<nav class="navbar fixed-top navbar-expand-lg navbar-light fixed-top bg-bluelight">
    <div class="container">
        <a class="navbar-brand" href="/index.html">
            Ali Shamsadini
        </a>
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse"
                data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false"
                aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
            <ul class="navbar-nav ml-auto">
                <li class="nav-item">
                    <a class="nav-link  " href="/"> <strong>Home</strong></a>
                </li>
                <li class="nav-item">
                    <a class="nav-link  " href="/education.html"> <strong>Education</strong></a>
                </li>
                <li class="nav-item">
                    <a class="nav-link  " href="/publications.html"> <strong>Publications</strong></a>
                </li>
                <li class="nav-item">
                    <a class="nav-link  " href="/experiences.html"> <strong>Experiences</strong></a>
                </li>
                <li class="nav-item">
                    <a class="nav-link  " href="/blog.html"> <strong>Blog</strong></a>
                </li>
            </ul>
        </div>
    </div>
</nav>
<!-- Header Slide -->
<!-- Page Content -->
<div class="container">
    <h1 class="my-4">
        Multi-Agent Deep Reinforcement Learning-Based Framework
        for Resource Management in Self-Organizing Networks
    </h1>
    <ol class="breadcrumb">
        <li class="breadcrumb-item">
            <a href="/index.html">Home</a>
        </li>
        <li class="breadcrumb-item active"><a href="/blog.html">Blog</a></li>
        <li class="breadcrumb-item active">Multi-Agent Deep Reinforcement Learning-Based Framework
            for Resource Management in Self-Organizing Networks
        </li>
    </ol>
    <hr>
    <div class="row justify-content-lg-center">
        <!-- Blog Entries Column -->
        <div class="col-lg-10 col-12">
            <!-- Blog Post -->
            <div class="my-3 text-muted">
                July 25, 2023
            </div>
            <div class="card-text"><p>This report was compiled as part of my comprehensive research on the application
                of reinforcement learning solutions in telecom networks. To obtain the full report, please feel free to
                contact me via email.</p>
                <hr/>
                <h4>Abstract</h4>
                <p>
                    In recent decades, mobile networks have expanded to provide coverage to as many people as possible.
                    Urban areas with higher user density typically enjoy better service coverage than less populated
                    areas, especially in the outskirts of cities. However, as continuous access to network services has
                    become a necessity, mobile phone operators are now extending their networks to reach users in remote
                    regions. Even in areas with adequate coverage, service quality can decline during peak times due to
                    network congestion and the limited resources of mobile operators. One possible solution is to
                    increase the density of cells to boost overall network capacity in such situations. While this
                    short-term oversupply of resources can enhance service quality, it results in long-term costsâ€”both
                    economically (upgrading new base stations and enhancing the network core) and environmentally
                    (providing energy to new base stations) for mobile operators. Therefore, solutions must be sought to
                    reduce the costs associated with deploying these resources while maintaining adequate service
                    quality. These solutions should account for dynamic demand for network resources, traffic patterns,
                    and, importantly, the spatiotemporal characteristics of mobile users. Within the life cycle of radio
                    networks, these issues fall under self-optimization problems. They include various approaches and
                    mechanisms to optimize key network parameters in real-time, using data from network cells. One of
                    the most widely recognized challenges, for which practical solutions have been implemented or are
                    being developed by leading operators worldwide, is the optimization of network cell coverage and
                    capacity. This challenge involves numerous adjustable parameters and complex dependencies that
                    cannot be effectively addressed using traditional AI methods. Recent research and practical
                    advancements have shown promise in solving such problems with large state spaces using deep
                    reinforcement learning approaches.
                </p>
                <h6 id="index-terms"><em>Index Terms</em>: Multi-agent Systems, Deep Reinforcement Learning,
                    Self-organizing Networks</h6>
                <h4>&#8544. INTRODUCTION</h4>
                <p>
                    Self-organizing networks were initially introduced by the 3GPP standardization organization to
                    streamline the planning, configuration, management, optimization, and troubleshooting of radio
                    access networks. This concept has evolved across various versions of the LTE and NGMN standards,
                    incorporating a suite of self-configuration, self-optimization, and self-healing solutions. Figure 1
                    illustrates the placement of these three solutions within the lifecycle of radio networks.
                <div class="row justify-content-center">
                    <div class="figure col col-sm-6 col-10 align-self-center my-4 img">
                        <img class="rounded" alt="Life Cycle of a Radio Network"
                             src="/assets/images/life-cycle-of-radio-network.svg"/>
                        <div class="figure-caption text-center text-dark">Fig. 1. Life Cycle of a Radio Network
                        </div>
                    </div>
                </div>
                <ul>
                    <li><strong>Self-configuration:</strong> This solution automates the introduction of new services
                        with minimal human intervention, integrating these functions into the planning and deployment
                        phases of radio networks.
                    </li>
                    <li><strong>Self-healing:</strong> Radio network elements are susceptible to errors and failures.
                        Self-healing functions focus on the maintenance phase of these elements. For instance, in the
                        event of a network cell failure, the services for users within the affected cell are
                        automatically transitioned to nearby cells with available capacity.
                    </li>
                    <li><strong>Self-optimization:</strong> Once network elements are designed, deployed, configured,
                        and connected to the network core, and after transitioning to operational mode, it is essential
                        to continuously enhance the efficiency of these elements. This improvement is performed in
                        real-time based on data received from network cells. In this proposed design, our primary focus
                        will be on the functions within this area.
                    </li>
                </ul>
                </p>
                <h4>&#8545. SUCCESSFUL RL USE CASES - SWISSCOM</h4>
                <p>
                    As Switzerland's largest telecommunications provider, offering a broad range of communication
                    services, Swisscom faces the challenge of reducing energy emissions in its existing low-band layers.
                    This energy reduction must be substantial enough to make room for the deployment of a new low-band
                    layer. Stringent Swiss government regulations governing the effective radiated power (ERP) of mobile
                    networks, combined with the power insufficiency in the new low-band layer and the coverage mismatch
                    with the existing layer, have pushed the company to adopt reinforcement learning (RL) approaches to
                    solve this issue. As illustrated in Figure 2, they first optimized the ERP parameter and then
                    addressed the RET (Remote Electrical Tilt) parameter in two distinct steps.
                <div class="row justify-content-center">
                    <div class="figure col col-sm-4 col-10 align-self-center my-4 img">
                        <img class="rounded" alt="Live Networks Utilizing Simulators and Emulators as Digital Twins"
                             src="/assets/images/live-networks-using-simulators-and-emulators-as-digital-twins.svg"/>
                        <div class="figure-caption text-center text-dark">Fig. 2. Live Networks Utilizing Simulators and
                            Emulators as Digital Twins
                        </div>
                    </div>
                </div>
                <ul>
                    <li><strong>Effective Radiated Power (ERP):</strong> Minimizing the ERP parameter as much as
                        possible while maintaining coverage and ensuring quality of service for users was achieved by
                        applying reinforcement learning techniques and utilizing a network simulator, which acted as a
                        digital counterpart.
                    </li>
                    <li><strong>Remote Electrical Tilt (RET):</strong> Optimizing the RET parameter was accomplished
                        through a simulator-based approach.
                    </li>
                </ul>
                The experiment focused on optimizing the transmission power of the uplink connection and adjusting the
                RET parameter in the Ticino region of Switzerland. This region includes 163 fourth-generation cells
                operating in the 800 MHz band, with 100 cells selected for uplink transmission power optimization,
                followed by RET parameter optimization. Reports indicated that the emulation of network behavior after
                power adjustments was remarkably accurate, removing the need for repeated online interactions with the
                network. Instead, the final optimized values were obtained exclusively through interactions with the
                digital counterpart, and these values were then directly implemented and integrated into the network.
                Subsequently, RET parameter optimization was applied, with the final modifications shown in Figure 3. As
                illustrated in Figure 3, in areas where network antennas consume maximum power, the antenna's electrical
                tilt is at its minimum, and vice versa.
                As a result of the testing, uplink transmission power was reduced by 10%, while uplink connection
                throughput increased by 12%. Additionally, after a single iteration of optimization and network
                interaction, cumulative transmission power was reduced by 20%, and uplink connection throughput
                increased by 5.5%. This reduction in the ERP parameter led to a 4.3% decrease in base station power
                consumption. Swisscom's experience is a prime example of how reinforcement learning approaches can be
                applied to learn, optimize, and ultimately automate complex processes without human intervention.
                <div class="row justify-content-center">
                    <div class="figure col col-sm-7 col-10 align-self-center my-4 img">
                        <img class="rounded" alt="Power and RET Adjustments in the Ticino Region of Switzerland"
                             src="/assets/images/power-and-RET-changes-in-the-Ticino-area-of-Switzerland.svg"/>
                        <div class="figure-caption text-center text-dark">Fig. 3. Power and RET Adjustments in the
                            Ticino Region of Switzerland
                        </div>
                    </div>
                </div>
                </p>
            </div>
            <hr>
            <div class="categories">
                <span class="badge badge-info">Multi-agent Systems</span>
                <span class="badge badge-info">Deep Reinforcement Learning</span>
                <span class="badge badge-info">Self-organizing Networks</span>
            </div>
            <hr>
            <div class="more-links mt-3">
                <h5 class="mb-1">Want to read more?</h5>
                Check out these pages:
                <ul class="mt-2">
                    <li>
                        <a href="https://www.ericsson.com/en/blog/2022/3/reinforcement-learning-solutions">
                            Bringing RL Solutions to Action in Telecom Networks</a>
                    </li>
                    <li>
                        <a href="https://www.ericsson.com/en/reports-and-papers/mobility-report/articles/reinforcement-learning">
                            Applying AI in Telecoms</a>
                    </li>
                    <li>
                        <a href="https://www.ericsson.com/en/blog/2023/11/reinforcement-learning">
                            Demystifying Online and offline RL</a>
                    </li>
                </ul>
            </div>
        </div>
    </div>
</div>
<!-- /.container -->
<!-- Footer -->
<footer class="py-3 bg-bluelight">
    <div class="container">
        <p class="m-0 text-center text-black txt-small">Copyright &copy; 2024, Ali Shamsadini</p>
    </div>
    <!-- /.container -->
</footer>
<!-- Bootstrap core JavaScript -->
<script src="/vendor/jquery/jquery.min.js"></script>
<script src="/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
<script src="/assets/js/custom.js"></script>
</body>
</html>
